{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PARSE GARD RESULTS ####\n",
    "## GROUP2 ##\n",
    "mypath='/Users/maeperez/Desktop/HYPHY/GROUP2/'\n",
    "allaln=[mypath+f for f in listdir(mypath) if f[-4:]=='.fna']\n",
    "onlyfiles = [mypath+f for f in listdir(mypath) if f[-8:]=='GTR.gard']\n",
    "# print [f[-8:] for f in listdir(mypath)]\n",
    "print 'There was a total of ',len(allaln),' files'\n",
    "print len(onlyfiles),'files ran GARD using GRT model'\n",
    "\n",
    "\n",
    "df=pd.DataFrame([],columns=['gene','GARD_result'])\n",
    "for file in onlyfiles:\n",
    "    gene = file.split('/')[-1].split('.')[0][8:]\n",
    "    page =  urllib.urlopen(file).read()\n",
    "    idx = page.find('GARD found')\n",
    "    entry = page[idx:idx+50].split('<')[0]\n",
    "    df=df.append({'gene':gene,'GARD_result':entry}, ignore_index=True)\n",
    "cat=Counter(df['GARD_result'])\n",
    "print '\\n'.join(sorted(['\\t'.join([k,str(v)]) for k,v in cat.items()]))\n",
    "df.to_csv('GROUP2/GARD_results.txt',header=True,index=False,sep='\\t')\n",
    "\n",
    "'''There was a total of  250  files\n",
    "213 files ran GARD using GRT model\n",
    "GARD found evidence of 1 breakpoints\t71\n",
    "GARD found evidence of 2 breakpoints\t22\n",
    "GARD found evidence of 3 breakpoints\t2\n",
    "GARD found evidence of 4 breakpoints\t3\n",
    "GARD found evidence of 5 breakpoints\t1\n",
    "GARD found evidence of 6 breakpoints\t1\n",
    "GARD found no evidence of recombination\t113'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a total of  647  files\n",
      "647 files ran GARD using GRT model\n",
      "647\n",
      "\n",
      "GARD found evidence of 1 breakpoints\t289\n",
      "GARD found evidence of 2 breakpoints\t34\n",
      "GARD found evidence of 3 breakpoints\t10\n",
      "GARD found evidence of 4 breakpoints\t4\n",
      "GARD found no evidence of recombination\t310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There was a total of  715  files\\n646 files ran GARD using GRT model\\n\\nGARD found evidence of 1 breakpoints\\t289\\nGARD found evidence of 2 breakpoints\\t34\\nGARD found evidence of 3 breakpoints\\t9\\nGARD found evidence of 4 breakpoints\\t4\\nGARD found no evidence of recombination\\t310'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### PARSE GARD RESULTS ####\n",
    "## GROUP1 ##\n",
    "\n",
    "mypath='/Users/maeperez/Desktop/HYPHY/GROUP1/'\n",
    "allaln=[mypath+f for f in listdir(mypath) if f[-4:]=='.fna']\n",
    "onlyfiles = [mypath+f for f in listdir(mypath) if f[-8:]=='GTR.gard']\n",
    "finished_files=[mypath+f for f in listdir(mypath) if f[-11:]=='gard_splits']\n",
    "# print [f[-8:] for f in listdir(mypath)]\n",
    "print 'There was a total of ',len(allaln),' files'\n",
    "print len(onlyfiles),'files ran GARD using GRT model'\n",
    "print len(finished_files)\n",
    "# print '\\n'.join(finished_files)\n",
    "\n",
    "\n",
    "print '\\n'.join(sorted(set([f.split('.')[0] for f in listdir(mypath) if f[-4:]=='.fna'])- set([f.split('.')[0] for f in listdir(mypath) if f[-8:]=='GTR.gard'])))\n",
    "\n",
    "df=pd.DataFrame([],columns=['gene','GARD_result'])\n",
    "for file in onlyfiles:\n",
    "    gene = file.split('/')[-1].split('.')[0][8:]\n",
    "    page =  urllib.urlopen(file).read()\n",
    "    idx = page.find('GARD found')\n",
    "    entry = page[idx:idx+50].split('<')[0]\n",
    "    df=df.append({'gene':gene,'GARD_result':entry}, ignore_index=True)\n",
    "cat=Counter(df['GARD_result'])\n",
    "print '\\n'.join(sorted(['\\t'.join([k,str(v)]) for k,v in cat.items()]))\n",
    "df.to_csv('GROUP1/GARD_results.txt',header=True,index=False,sep='\\t')\n",
    "\n",
    "\n",
    "'''There was a total of  715  files\n",
    "646 files ran GARD using GRT model\n",
    "\n",
    "GARD found evidence of 1 breakpoints\t289\n",
    "GARD found evidence of 2 breakpoints\t34\n",
    "GARD found evidence of 3 breakpoints\t9\n",
    "GARD found evidence of 4 breakpoints\t4\n",
    "GARD found no evidence of recombination\t310'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of genes that ran GARD 647\n",
      "number of genes that failed KH test  61\n",
      "number of genes that ran GARD 68\n",
      "number of genes that failed KH test  3\n"
     ]
    }
   ],
   "source": [
    "#### PARSE KH test RESULTS ####\n",
    "## GROUP1 ##\n",
    "mypath='/Users/maeperez/Desktop/HYPHY/GROUP1/'\n",
    "onlyfiles = [mypath+f for f in listdir(mypath) if f[-7:]=='.KHtest']\n",
    "kh=pd.DataFrame([],columns=['Gene','p0.01','p0.05','p0.1'])\n",
    "print 'number of genes that ran GARD',len(onlyfiles)\n",
    "for i in range(len(onlyfiles)):\n",
    "# for i in [0]:\n",
    "    with open(onlyfiles[i]) as f:\n",
    "        gene=re.split('/|\\.|aligned_',onlyfiles[i])[-3]\n",
    "        lines=f.read().splitlines()\n",
    "        for n in reversed(range(len(lines))):\n",
    "            if lines[n][:6]=='At p =':\n",
    "#                 print lines[n-2]\n",
    "#                 print lines[n-1]\n",
    "#                 print lines[n]\n",
    "                try:\n",
    "                    p001= int(lines[n-2].split(' ')[-3])\n",
    "                    p005= int(lines[n-1].split(' ')[-3])\n",
    "                    p01= int(lines[n].split(' ')[-3])\n",
    "                except:\n",
    "                    p001= np.nan\n",
    "                    p005= np.nan\n",
    "                    p01= np.nan\n",
    "                break\n",
    "        newentry=dict(zip(['Gene','p0.01','p0.05','p0.1'],[gene,p001,p005,p01]))\n",
    "        kh=kh.append(newentry,ignore_index=True)\n",
    "\n",
    "\n",
    "print 'number of genes that failed KH test ',len(kh.loc[kh['p0.05']>0])\n",
    "kh.to_csv('GROUP1/KHtest_results.txt')\n",
    "\n",
    "## GROUP1/HKY ##\n",
    "mypath='/Users/maeperez/Desktop/HYPHY/GROUP1/HKY/'\n",
    "onlyfiles = [mypath+f for f in listdir(mypath) if f[-7:]=='.KHtest']\n",
    "kh=pd.DataFrame([],columns=['Gene','p0.01','p0.05','p0.1'])\n",
    "print 'number of genes that ran GARD',len(onlyfiles)\n",
    "for i in range(len(onlyfiles)):\n",
    "# for i in [0]:\n",
    "    with open(onlyfiles[i]) as f:\n",
    "        gene=re.split('/|\\.|aligned_',onlyfiles[i])[-3]\n",
    "        lines=f.read().splitlines()\n",
    "        for n in reversed(range(len(lines))):\n",
    "            if lines[n][:6]=='At p =':\n",
    "#                 print lines[n-2]\n",
    "#                 print lines[n-1]\n",
    "#                 print lines[n]\n",
    "                try:\n",
    "                    p001= int(lines[n-2].split(' ')[-3])\n",
    "                    p005= int(lines[n-1].split(' ')[-3])\n",
    "                    p01= int(lines[n].split(' ')[-3])\n",
    "                except:\n",
    "                    p001= np.nan\n",
    "                    p005= np.nan\n",
    "                    p01= np.nan\n",
    "                break\n",
    "        newentry=dict(zip(['Gene','p0.01','p0.05','p0.1'],[gene,p001,p005,p01]))\n",
    "        kh=kh.append(newentry,ignore_index=True)\n",
    "\n",
    "\n",
    "print 'number of genes that failed KH test ',len(kh.loc[kh['p0.05']>0])\n",
    "kh.to_csv(mypath+'KHtest_results.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAY24_RS10490</td>\n",
       "      <td>heme lyase CcmF/NrfE family subunit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAY24_RS10495</td>\n",
       "      <td>cytochrome c maturation protein CcmE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAY24_RS11160</td>\n",
       "      <td>N-acetyl-gamma-glutamyl-phosphate reductase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gene                                      Product\n",
       "0  AAY24_RS10490          heme lyase CcmF/NrfE family subunit\n",
       "1  AAY24_RS10495         cytochrome c maturation protein CcmE\n",
       "2  AAY24_RS11160  N-acetyl-gamma-glutamyl-phosphate reductase"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta=pd.read_csv('ref_gene2product.txt',header=0,sep='\\t')\n",
    "meta[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PARSE aBSRel RESULTS ####\n",
    "## GROUP2 ##\n",
    "'''pd.set_option('display.max_rows', 500)\n",
    "bsrel_GRP2=pd.read_csv('GROUP2/bsrel_all_results.txt',header=0,sep=' ')\n",
    "print len(bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]['Gene'])\n",
    "print len(set(bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]['Gene']))\n",
    "bsrel_GRP2['Gene']=bsrel_GRP2['Gene'].apply(lambda x: str(x)[8:-6])\n",
    "\n",
    "bsrel_GRP2=pd.merge(bsrel_GRP2, meta, on='Gene')\n",
    "# print '\\n'.join([' '.join(item) for item in map(list, zip(set(bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]['Gene']),set(bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]['Product'])))])\n",
    "sel_bsrel_GRP2=bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]\n",
    "bsrel_GRP2.to_csv('GROUP2/bsrel_group2_results_products.txt',header=True,index=False,sep='\\t')\n",
    "sel_bsrel_GRP2.sort_values('Gene')'''\n",
    "\n",
    "## HKY ##\n",
    "pd.set_option('display.max_rows', 500)\n",
    "bsrel_GRP2=pd.read_csv('GROUP2/HKY/bsrel_all_results.txt',header=0,sep=' ')\n",
    "print len(bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]['Gene'])\n",
    "print len(set(bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]['Gene']))\n",
    "bsrel_GRP2['Gene']=bsrel_GRP2['Gene'].apply(lambda x: str(x)[8:-10])\n",
    "bsrel_GRP2=pd.merge(bsrel_GRP2, meta, on='Gene')\n",
    "# print '\\n'.join([' '.join(item) for item in map(list, zip(set(bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]['Gene']),set(bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]['Product'])))])\n",
    "sel_bsrel_GRP2=bsrel_GRP2.loc[bsrel_GRP2['p_Holm']<=0.05]\n",
    "bsrel_GRP2.to_csv('GROUP2/HKY/bsrel_group2_results_products.txt',header=True,index=False,sep='\\t')\n",
    "sel_bsrel_GRP2.sort_values('Gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "#### PARSE aBSRel RESULTS ####\n",
    "## GROUP1 ##\n",
    "pd.set_option('display.max_rows', 500)\n",
    "bsrel_GRP1=pd.read_csv('GROUP1/bsrel_all_results.txt',header=0,sep=' ')\n",
    "print len(bsrel_GRP1.loc[bsrel_GRP1['p_Holm']<=0.05]['Gene'])\n",
    "print len(set(bsrel_GRP1.loc[bsrel_GRP1['p_Holm']<=0.05]['Gene']))\n",
    "bsrel_GRP1['Gene']=bsrel_GRP1['Gene'].apply(lambda x: str(x)[8:-6])\n",
    "bsrel_GRP1['Model']='GTR'\n",
    "# bsrel_GRP1=pd.merge(bsrel_GRP1, meta, on='Gene')\n",
    "# sel_bsrel_GRP1=bsrel_GRP1.loc[bsrel_GRP1['p_Holm']<=0.05]\n",
    "# bsrel_GRP1.to_csv('GROUP1/bsrel_group1_results_products.txt',header=True,index=False,sep='\\t')\n",
    "# sel_bsrel_GRP1.sort_values('Gene')\n",
    "\n",
    "## HKY ##\n",
    "pd.set_option('display.max_rows', 500)\n",
    "bsrel_GRP1_hky=pd.read_csv('GROUP1/HKY/bsrel_all_results.txt',header=0,sep=' ')\n",
    "# print len(bsrel_GRP1.loc[bsrel_GRP1['p_Holm']<=0.05]['Gene'])\n",
    "# print len(set(bsrel_GRP1.loc[bsrel_GRP1['p_Holm']<=0.05]['Gene']))\n",
    "bsrel_GRP1_hky['Gene']=bsrel_GRP1_hky['Gene'].apply(lambda x: str(x)[8:-10])\n",
    "bsrel_GRP1_hky['Model']='HKY'\n",
    "\n",
    "bsrel_GRP1=pd.concat([bsrel_GRP1, bsrel_GRP1_hky])\n",
    "bsrel_GRP1.to_csv('GROUP1_aBSRel_results.txt',header=True,index=False,sep='\\t')\n",
    "# print '\\n'.join([' '.join(item) for item in map(list, zip(set(bsrel_GRP1.loc[bsrel_GRP1['p_Holm']<=0.05]['Gene']),set(bsrel_GRP1.loc[bsrel_GRP1['p_Holm']<=0.05]['Product'])))])\n",
    "# sel_bsrel_GRP1=bsrel_GRP1.loc[bsrel_GRP1['p_Holm']<=0.05]\n",
    "# bsrel_GRP1.to_csv('GROUP1/HKY/bsrel_group1_results_products.txt',header=True,index=False,sep='\\t')\n",
    "# sel_bsrel_GRP1.sort_values('Gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PARSE aBSRel RESULTS ####\n",
    "## old pipeline ##\n",
    "# bsrel_Pipeline=pd.read_csv('../pipeline/bsrel_all_results.txt',header=0,sep=' ')\n",
    "# print len(bsrel_Pipeline.loc[bsrel_Pipeline['p_Holm']<=0.05]['Gene'])\n",
    "# print len(set(bsrel_Pipeline.loc[bsrel_Pipeline['p_Holm']<=0.05]['Gene']))\n",
    "\n",
    "# mypath='/Users/maeperez/Desktop/pipeline/'\n",
    "# allaln=[mypath+f for f in listdir(mypath) if f[-13:]=='.nostop.fasta']\n",
    "# # print [mypath+f[-13:] for f in listdir(mypath)]\n",
    "# onlyfiles = [mypath+f for f in listdir(mypath) if f[-10:]=='fasta.GARD']\n",
    "# # print [f[-10:] for f in listdir(mypath)]\n",
    "# print 'There was a total of ',len(allaln),' files'\n",
    "# print len(onlyfiles),'files ran GARD using GRT model'\n",
    "\n",
    "# i=[]\n",
    "# df2=pd.DataFrame([],columns=['gene','GARD_result'])\n",
    "# for file in onlyfiles:\n",
    "#     gene = file.split('/')[-1]\n",
    "# #     print file.split('/')[-1]\n",
    "#     page =  urllib.urlopen(file).read()\n",
    "#     idx = page.find('GARD found')\n",
    "#     entry = page[idx:idx+50].split('<')[0]\n",
    "#     i+=[entry]\n",
    "#     df2=df2.append({'gene':gene,'GARD_result':entry}, ignore_index=True)\n",
    "# cat=Counter(df2['GARD_result'])\n",
    "# print '\\n'.join(sorted(['\\t'.join([k,str(v)]) for k,v in cat.items()]))\n",
    "# df2.to_csv('pipeline_GARD_results.txt',header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PARSE GARD RESULTS ####\n",
    "## GROUP2 ##\n",
    "mypath='/Users/maeperez/Desktop/HYPHY/GROUP2/'\n",
    "allaln=[mypath+f for f in listdir(mypath) if f[-4:]=='.fna']\n",
    "onlyfiles = [mypath+f for f in listdir(mypath) if f[-8:]=='GTR.gard']\n",
    "# print [f[-8:] for f in listdir(mypath)]\n",
    "print 'There was a total of ',len(allaln),' files'\n",
    "print len(onlyfiles),'files ran GARD using GRT model'\n",
    "\n",
    "\n",
    "df=pd.DataFrame([],columns=['gene','GARD_result'])\n",
    "for file in onlyfiles:\n",
    "    gene = file.split('/')[-1].split('.')[0][8:]\n",
    "    page =  urllib.urlopen(file).read()\n",
    "    idx = page.find('GARD found')\n",
    "    entry = page[idx:idx+50].split('<')[0]\n",
    "    df=df.append({'gene':gene,'GARD_result':entry}, ignore_index=True)\n",
    "cat=Counter(df['GARD_result'])\n",
    "print '\\n'.join(sorted(['\\t'.join([k,str(v)]) for k,v in cat.items()]))\n",
    "df.to_csv('GROUP2/GARD_results.txt',header=True,index=False,sep='\\t')\n",
    "\n",
    "'''There was a total of  250  files\n",
    "213 files ran GARD using GRT model\n",
    "GARD found evidence of 1 breakpoints\t71\n",
    "GARD found evidence of 2 breakpoints\t22\n",
    "GARD found evidence of 3 breakpoints\t2\n",
    "GARD found evidence of 4 breakpoints\t3\n",
    "GARD found evidence of 5 breakpoints\t1\n",
    "GARD found evidence of 6 breakpoints\t1\n",
    "GARD found no evidence of recombination\t113'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a total of  67  files\n",
      "68 files ran GARD using HKY model\n",
      "55\n",
      "set(['aligned_Rmag_0077', 'aligned_Rmag_0286', 'aligned_Rmag_0767', 'aligned_Rmag_0178', 'aligned_Rmag_0659', 'aligned_Rmag_0160', 'aligned_Rmag_0701', 'aligned_Rmag_0570', 'aligned_Rmag_0990', 'aligned_Rmag_0595', 'aligned_Rmag_0884', 'aligned_Rmag_0741', 'aligned_Rmag_0853'])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There was a total of  715  files\\n646 files ran GARD using GRT model\\n\\nGARD found evidence of 1 breakpoints\\t289\\nGARD found evidence of 2 breakpoints\\t34\\nGARD found evidence of 3 breakpoints\\t9\\nGARD found evidence of 4 breakpoints\\t4\\nGARD found no evidence of recombination\\t310'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### PARSE GARD RESULTS ####\n",
    "## GROUP1 - HKY ##\n",
    "\n",
    "mypath='/Users/maeperez/Desktop/HYPHY/GROUP1/HKY/'\n",
    "allaln=[mypath+f for f in listdir(mypath) if f[-4:]=='.fna']\n",
    "onlyfiles = [mypath+f for f in listdir(mypath) if f[-8:]=='HKY.gard']\n",
    "finished_files=[mypath+f for f in listdir(mypath) if f[-11:]=='gard_splits']\n",
    "# print [f[-8:] for f in listdir(mypath)]\n",
    "print 'There was a total of ',len(allaln),' files'\n",
    "print len(onlyfiles),'files ran GARD using HKY model'\n",
    "print len(finished_files)\n",
    "print set([f.split('.')[0] for f in listdir(mypath) if f[-8:]=='HKY.gard']) - set([f.split('.')[0] for f in listdir(mypath) if f[-11:]=='gard_splits'])\n",
    "# print '\\n'.join(finished_files)\n",
    "\n",
    "\n",
    "print '\\n'.join(sorted(set([f.split('.')[0] for f in listdir(mypath) if f[-4:]=='.fna'])- set([f.split('.')[0] for f in listdir(mypath) if f[-8:]=='HKY.gard'])))\n",
    "\n",
    "df=pd.DataFrame([],columns=['gene','GARD_result'])\n",
    "for file in onlyfiles:\n",
    "    gene = file.split('/')[-1].split('.')[0][8:]\n",
    "    page =  urllib.urlopen(file).read()\n",
    "    idx = page.find('GARD found')\n",
    "    entry = page[idx:idx+50].split('<')[0]\n",
    "    df=df.append({'gene':gene,'GARD_result':entry}, ignore_index=True)\n",
    "cat=Counter(df['GARD_result'])\n",
    "# print '\\n'.join(sorted(['\\t'.join([k,str(v)]) for k,v in cat.items()]))\n",
    "df.to_csv(mypath+'/GARD_results.txt',header=True,index=False,sep='\\t')\n",
    "\n",
    "\n",
    "'''There was a total of  715  files\n",
    "646 files ran GARD using GRT model\n",
    "\n",
    "GARD found evidence of 1 breakpoints\t289\n",
    "GARD found evidence of 2 breakpoints\t34\n",
    "GARD found evidence of 3 breakpoints\t9\n",
    "GARD found evidence of 4 breakpoints\t4\n",
    "GARD found no evidence of recombination\t310'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a total of  37  files\n",
      "33 files ran GARD using HKY model\n",
      "26\n",
      "AAY24_RS12335\n",
      "AAY24_RS16890\n",
      "AAY24_RS17730\n",
      "AAY24_RS17790\n"
     ]
    }
   ],
   "source": [
    "## GROUP2 - HKY ##\n",
    "mypath='/Users/maeperez/Desktop/HYPHY/GROUP2/HKY/'\n",
    "allaln=[mypath+f for f in listdir(mypath) if f[-4:]=='.fna']\n",
    "onlyfiles = [mypath+f for f in listdir(mypath) if f[-8:]=='HKY.gard']\n",
    "finished_files=[mypath+f for f in listdir(mypath) if f[-11:]=='gard_splits']\n",
    "# print [f[-8:] for f in listdir(mypath)]\n",
    "print 'There was a total of ',len(allaln),' files'\n",
    "print len(onlyfiles),'files ran GARD using HKY model'\n",
    "print len(finished_files)\n",
    "# print '\\n'.join(finished_files)\n",
    "\n",
    "\n",
    "print '\\n'.join(sorted(set([f.split('.')[0] for f in listdir(mypath) if f[-4:]=='.fna'])- set([f.split('.')[0] for f in listdir(mypath) if f[-8:]=='HKY.gard'])))\n",
    "\n",
    "df=pd.DataFrame([],columns=['gene','GARD_result'])\n",
    "for file in onlyfiles:\n",
    "    gene = file.split('/')[-1].split('.')[0][8:]\n",
    "    page =  urllib.urlopen(file).read()\n",
    "    idx = page.find('GARD found')\n",
    "    entry = page[idx:idx+50].split('<')[0]\n",
    "    df=df.append({'gene':gene,'GARD_result':entry}, ignore_index=True)\n",
    "cat=Counter(df['GARD_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
